{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e28bd2df",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f08a1a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipelines.dataset import SignDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6550c534",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_file = '../data/dummy_wlasl/wlasl_amaglgam.JSON'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f6d35d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SignDataset(ann_file=ann_file,\n",
    "                     root_dir='../data/dummy_wlasl/rawframes/',\n",
    "                     split='test',\n",
    "                     clip_len=16,\n",
    "                     frame_interval=4,\n",
    "                     num_clips=1,\n",
    "                     resolution=224,\n",
    "                     test_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "61d4ef90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 16, 224, 224])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accident 0\n",
    "accident_0 = dataset[0][0]\n",
    "accident_0.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a1a948",
   "metadata": {},
   "source": [
    "## Trimming the transformer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4dc9d42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('model/vit-base-p16_videomaev2-vit-g-dist-k710-pre_16x4x1_kinetics-400_20230510-3e7f93b2.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2f103bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from model.cls_head import ClassifierHead\n",
    "from model.vit_mae import VisionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "db544377",
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone = VisionTransformer(\n",
    "                            img_size=224,\n",
    "                            patch_size=16,\n",
    "                            embed_dims=768,\n",
    "                            depth=12,\n",
    "                            num_heads=12,\n",
    "                            mlp_ratio=4,\n",
    "                            qkv_bias=True,\n",
    "                            num_frames=16,\n",
    "                            norm_cfg=dict(type='LN', eps=1e-6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f94d8231",
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_head = ClassifierHead(in_features=768,\n",
    "                         num_classes=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bf7120cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoMAE(nn.Module):\n",
    "    def __init__(self, backbone, cls_head):\n",
    "        super(VideoMAE, self).__init__()\n",
    "        self.backbone = backbone\n",
    "        self.cls_head = cls_head\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = self.cls_head(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fd0f33ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VideoMAE(backbone, cls_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "660b83f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  ...,  1.0000e+00,\n",
       "           0.0000e+00,  1.0000e+00],\n",
       "         [ 8.4147e-01,  5.4030e-01,  8.2843e-01,  ...,  1.0000e+00,\n",
       "           1.0243e-04,  1.0000e+00],\n",
       "         [ 9.0930e-01, -4.1615e-01,  9.2799e-01,  ...,  1.0000e+00,\n",
       "           2.0486e-04,  1.0000e+00],\n",
       "         ...,\n",
       "         [ 4.6785e-01,  8.8381e-01,  8.8921e-01,  ...,  9.8655e-01,\n",
       "           1.5961e-01,  9.8718e-01],\n",
       "         [ 9.9648e-01,  8.3839e-02,  8.7704e-01,  ...,  9.8653e-01,\n",
       "           1.5971e-01,  9.8716e-01],\n",
       "         [ 6.0895e-01, -7.9321e-01,  9.3232e-02,  ...,  9.8652e-01,\n",
       "           1.5982e-01,  9.8715e-01]]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backbone.pos_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "aeb56545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['backbone.pos_embed'], unexpected_keys=[])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(checkpoint, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0716cc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "value = model.backbone(accident_0.unsqueeze(dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a9a51ac2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmsign",
   "language": "python",
   "name": "mmsign"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
